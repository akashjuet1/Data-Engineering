package com.sundogsoftware.spark

import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.spark.sql._
import org.apache.log4j._

object crime {
  


   def main(args: Array[String]): Unit = {
    
    // Set the log level to only print errors
    Logger.getLogger("org").setLevel(Level.ERROR)
    
    // Use new SparkSession interface in Spark 2.0
    val spark = SparkSession
      .builder
      .appName("SparkSQL")
      .master("local[*]")
      .config("spark.sql.warehouse.dir", "file:///C:/temp") // Necessary to work around a Windows bug in Spark 2.0.0; omit if you're not on Windows.
      .getOrCreate()
   
  
   val crime = spark.read.format("csv")    // uploading a csv file as data frame
  .option("inferSchema", "true")
  .option("header", "true")
  .load("file:///c:/SparkScala/crime13.csv")
    
    
    import spark.implicits._
   //val sPeople = crime.toDS
    
    crime.show()
    
    crime.createOrReplaceTempView("crime13")
  
   val totalCrimes = spark.sql("select month,count(crimetyp) as cnt from crime13 group by month order by cnt").show()
   
   val crimeTypLoc = spark.sql("select loc,max(crimetyp) as maxcrime from crime13 group by loc").show()
   
   val crimeno = spark.sql("select crimetyp, count(crimetyp) as cnt from crime13 group by crimetyp order by cnt").show()
   
   val locCrimeCount = spark.sql("select crimetyp,max(loc) as cnt from crime13 group by crimetyp").show()
   
   }
}
